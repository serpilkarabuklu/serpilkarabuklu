---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About me

  I am a post-doctoral researcher at  [Toyota Technological Institute at Chicago (TTIC)](https://ttic.edu/) which is a philanthropically endowed academic computer science institute. I am part of both [Speech & Language group (SL@TTIC)](https://slattic.ttic.edu/) and [Perception and Learning Systems (PALS)](https://pals.ttic.edu/) groups. 
  
  As an interdisciplinary researcher working on sign languages, my research focuses on how human mind organizes visual modality and uses its simultaneous nature to realize the semantic and pragmatic notions across languages and populations. I am specifically interested in how manual domain (hands) and nonmanual domain (face and body movements) are modulated to convey semantic notions such as certainty, information structure, or prominence and (a)typicality across languages such as American Sign Language (ASL), Turkish Sign Language (TÄ°D), Nicaraguan Sign Language (LSN), and populations such as early acquirers, late acquirers, or emerging sign language users. I am currently extending my skillset to computational models trained on sign languages and to test their capacity to capture this simultaneous nature. 
  
  I was previously a post-doctoral researcher at Dr. Diane Brentari's [Sign Language Linguistics Laboratory](https://signlanguagelab.uchicago.edu/) at the Department of Linguistics at the University of Chicago. I received my Ph.D. from the Department of Linguistics at Purdue University under Dr. [Ronnie B. Wilbur's](https://www.cla.purdue.edu/directory/profiles/ronnie-wilbur.html) supervision. If you want to know more about my research, you can find my CV [here](https://serpilkarabuklu.github.io/files/Karabuklu_CV.pdf). 
  
   While not working on sign languages, you can find me exploring the city with my retriever-mix rescue dog, Oscar, going on hikes, swimming, or picking up a new hobby.

## ðŸ—ž News
------
ðŸ—¨ __January 2026__ I will be presenting my work with Diane Brentari on [prominence and atypicality in ASL and TÄ°D](https://web.cvent.com/event/d453188a-a321-46d4-b57e-79d5067e6521/websitePage:0fce7914-bbae-47fb-991c-3050b18e5787) at [LSA 2026](https://web.cvent.com/event/d453188a-a321-46d4-b57e-79d5067e6521/websitePage:0fce7914-bbae-47fb-991c-3050b18e5787). Excited to meet and catch up with friends, and make new!

ðŸ—¨ __November 2025__ I shared my pose estimation study findings on [head nods in ASL and TÄ°D](https://sign-language-grammars-parsers-brain.github.io/abstracts/Karabuklu%20-%20Form%20and%20Meaning%20Relations%20of%20Head%20Nods%20Across%20Sign%20Languages.pdf) at [Sign Langauge Grammars, Parsing Models, and the Brain Workshop](https://sign-language-grammars-parsers-brain.github.io/).

ðŸ—¨ __October 2025__ I presented how sign language affects signers' and learners' production and perception at [APS Roundtable Perceiving Motion, Producing Meaning](https://app.socio.events/NTYxNDc/Agenda/479976/Session/1321069).

ðŸ—¨ __October 2025__ I presented how prominence shapes simultaneity in ASL and TÄ°D at [the University of Chicago Center for Gesture, Sign, and Language Mini Conference](https://voices.uchicago.edu/cgsl/events/).

ðŸ’° __May 2025__ Along with Austin German and Jeff Davis, we received a small grant from the Center for Gesture, Sign, and Language at the University of Chicago to investigate the effects of animacy on word order across languages, ASL, TÄ°D, LSN, and Z Sign. Stay tuned for the results!

